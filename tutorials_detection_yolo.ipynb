{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osTQZUCg-vQF"
   },
   "source": [
    "# Tutorial: VisionKG - A Data-Centric Way to Train your own Obejct Detection Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Local Data from Annotator\n",
    "local_annotation_path = '/home/mb/YOLO/dellData/annotation.json'\n",
    "local_data_path = '/home/mb/YOLO/dellData/'\n",
    "\n",
    "# where to save your data\n",
    "output_image_directory = '/home/mb/YOLO/data/processedDell/images/train/'\n",
    "output_annotation_directory = '/home/mb/YOLO/data/processedDell/annotations/'\n",
    "\n",
    "# your all-in-one json file\n",
    "dell_annotations = '/home/mb/YOLO/data/processedDell/annotations//annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def process_coco_annotations(coco_file_path, output_dir, local_data_path, output_annotation_directory):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(output_annotation_directory, exist_ok=True)\n",
    "    with open(coco_file_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "\n",
    "    old_id_to_new_id = {cat['id']: i+1 for i, cat in enumerate(sorted(coco_data['categories'], key=lambda x: x['id']))}\n",
    "\n",
    "    for cat in coco_data['categories']:\n",
    "        cat['id'] = old_id_to_new_id[cat['id']]\n",
    "\n",
    "    for ann in coco_data['annotations']:\n",
    "        ann['category_id'] = old_id_to_new_id[ann['category_id']]\n",
    "\n",
    "    for img in coco_data['images']:\n",
    "        old_image_path = local_data_path + '/' + img['file_name'] \n",
    "        new_image_path = os.path.join(output_dir, os.path.basename(old_image_path))\n",
    "\n",
    "        if os.path.exists(old_image_path):\n",
    "            shutil.copy(old_image_path, new_image_path)\n",
    "        else:\n",
    "            print(f\" Warning: {old_image_path} is not exited.\")\n",
    "\n",
    "        img['image_path'] = new_image_path\n",
    "        img['file_name'] = os.path.basename(new_image_path)\n",
    "\n",
    "    output_json_path = os.path.join(output_annotation_directory, \"annotations.json\")\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(coco_data, f, indent=4)\n",
    "\n",
    "    print(f\"Process done! Annotations have been saved to: {output_json_path}\")\n",
    "    print(f\"All the images have been saved to: {output_dir}\")\n",
    "    \n",
    "    return coco_data\n",
    "processed_dell_data = process_coco_annotations(local_annotation_path, output_image_directory, local_data_path, output_annotation_directory)\n",
    "\n",
    "dell_categories = [i['name'] for i in processed_dell_data['categories']]\n",
    "print(dell_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vHWnyaMpSECR"
   },
   "source": [
    "# 1. QuickView of VisionKG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZQeO_4WCxd2"
   },
   "source": [
    "## 1.2 Query a Dataset as YOU need via VisionKG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install git+https://github.com/cqels/vision.git --force\n",
    "# path to your yolo directory\n",
    "%cd /home/mb/YOLO/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSaW9721CXPE"
   },
   "source": [
    "# 2. Object Detection in Practice starting from VisionKG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ4e_tlQ6R20"
   },
   "source": [
    "## 2.1 Prepare and set parameters for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38x2pe0OSECd"
   },
   "outputs": [],
   "source": [
    "from os.path import join as opj\n",
    "from shutil import copy\n",
    "from torch_model_zoo import utils\n",
    "\n",
    "path_to_anno_mixedDatasets = dell_annotations\n",
    "filter_cat_nms = dell_categories\n",
    "params = utils.prepare_for_training(path_to_anno_mixedDatasets, processed_dell_data, existed_data=output_image_directory, filter_cat_nms=filter_cat_nms)\n",
    "    \n",
    "nms_categories = params['CAT_NMS']\n",
    "num_categories = len(nms_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move data\n",
    "\n",
    "annotation_path = output_annotation_directory\n",
    "# I want to let img_path is the father folder of output_image_directory\n",
    "img_path = opj(output_image_directory, '..')\n",
    "\n",
    "anno_files = ['train.json','val.json', 'test.json']\n",
    "img_folders = ['train2017', 'val2017', 'test2017']\n",
    "\n",
    "for anno_file, img_folder in zip(anno_files, img_folders):\n",
    "    anno_file_ = opj(annotation_path, anno_file)\n",
    "    new_anno_file = opj(annotation_path, 'instances_' + anno_file.split('.')[0] + '2017.json')\n",
    "    img_folder = opj(img_path, img_folder)\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "    with open(anno_file_, 'r') as f:\n",
    "        anno = json.load(f)\n",
    "    # save anno to new_anno_file\n",
    "    with open(new_anno_file, 'w') as f:\n",
    "        json.dump(anno, f, indent=4)\n",
    "    for img in anno['images']:\n",
    "        img_name = img['file_name']\n",
    "        raw_img_path = opj(local_data_path, img_name)\n",
    "        dst_img_path = opj(img_folder, img_name)\n",
    "        copy(raw_img_path, dst_img_path)\n",
    "    print(f\"Images in {raw_img_path} have been moved to {dst_img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit config file\n",
    "import yaml\n",
    "config_path = 'yolo/config/dataset/dellData.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    config['class_num'] = num_categories\n",
    "    config['class_list'] = nms_categories\n",
    "# save config\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=None, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwujjB2hLyk_"
   },
   "source": [
    "## 2.2 Data-Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSxR5mGTL1Cg"
   },
   "outputs": [],
   "source": [
    "if num_categories > 4:\n",
    "  cat_nms = nms_categories[0:4]\n",
    "else:\n",
    "  cat_nms = nms_categories\n",
    "utils.show_annotation(path_to_anno_mixedDatasets, cat_nms, show_num=6)\n",
    "utils.show_cat_distribution(path_to_anno_mixedDatasets, cat_nms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HNbl_TRC5q8"
   },
   "source": [
    "## 2.2 Perform Training & Evaluation on your chosen Object Detection tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y6E_Vv_OVQHV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/10/25 00:07:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ðŸ“„ Created log folder: <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold; text-decoration: underline\">runs/train/v9-dev</span>                          <a href=\"file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/logging_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">logging_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/logging_utils.py#324\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">324</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/10/25 00:07:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ðŸ“„ Created log folder: \u001b[1;4;34mruns/train/v9-dev\u001b[0m                          \u001b]8;id=665275;file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/logging_utils.py\u001b\\\u001b[2mlogging_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=110420;file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/logging_utils.py#324\u001b\\\u001b[2m324\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> ðŸ“ˆ Enable Model EMA                                                  <a href=\"file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/model_utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">model_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/model_utils.py#43\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">43</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m ðŸ“ˆ Enable Model EMA                                                  \u001b]8;id=992960;file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/model_utils.py\u001b\\\u001b[2mmodel_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=859731;file:///jicheng_workspace/jicheng_notebook/YOLO/yolo/utils/model_utils.py#43\u001b\\\u001b[2m43\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_path:  runs/train/v9-dev\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/10/25 00:07:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> âš¡ Using 16bit Automatic Mixed Precision <span style=\"font-weight: bold\">(</span>AMP<span style=\"font-weight: bold\">)</span>            <a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">accelerator_connector.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py#520\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">520</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/10/25 00:07:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m âš¡ Using 16bit Automatic Mixed Precision \u001b[1m(\u001b[0mAMP\u001b[1m)\u001b[0m            \u001b]8;id=675844;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py\u001b\\\u001b[2maccelerator_connector.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=923086;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py#520\u001b\\\u001b[2m520\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 00:07:36,546][lightning.pytorch.utilities.rank_zero][INFO] - Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> âš¡ Trainer already configured with model summary callbacks:  <a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callback_connector.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py#102\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"font-weight: bold\">[&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'yolo.utils.logging_utils.YOLORichModelSummary'</span><span style=\"font-weight: bold\">&gt;]</span>.   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         Skipping setting a default `ModelSummary` callback.          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m âš¡ Trainer already configured with model summary callbacks:  \u001b]8;id=561067;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py\u001b\\\u001b[2mcallback_connector.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=785597;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/callback_connector.py#102\u001b\\\u001b[2m102\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[1m[\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'yolo.utils.logging_utils.YOLORichModelSummary'\u001b[0m\u001b[1m>\u001b[0m\u001b[1m]\u001b[0m.   \u001b[2m                         \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         Skipping setting a default `ModelSummary` callback.          \u001b[2m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Trainer already configured with model summary callbacks: [<class 'yolo.utils.logging_utils.YOLORichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 00:07:36,554][lightning.pytorch.utilities.rank_zero][INFO] - Trainer already configured with model summary callbacks: [<class 'yolo.utils.logging_utils.YOLORichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> âš¡ GPU available: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> <span style=\"font-weight: bold\">(</span>cuda<span style=\"font-weight: bold\">)</span>, used: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>                                 <a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">setup.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py#156\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m âš¡ GPU available: \u001b[3;92mTrue\u001b[0m \u001b[1m(\u001b[0mcuda\u001b[1m)\u001b[0m, used: \u001b[3;92mTrue\u001b[0m                                 \u001b]8;id=266355;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py\u001b\\\u001b[2msetup.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=685253;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py#156\u001b\\\u001b[2m156\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 00:07:36,569][lightning.pytorch.utilities.rank_zero][INFO] - GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> âš¡ TPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> TPU cores                               <a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">setup.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py#159\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m âš¡ TPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m TPU cores                               \u001b]8;id=71961;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py\u001b\\\u001b[2msetup.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=977991;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py#159\u001b\\\u001b[2m159\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 00:07:36,573][lightning.pytorch.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> âš¡ HPU available: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, using: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> HPUs                                    <a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">setup.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py#169\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m âš¡ HPU available: \u001b[3;91mFalse\u001b[0m, using: \u001b[1;36m0\u001b[0m HPUs                                    \u001b]8;id=346267;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py\u001b\\\u001b[2msetup.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=835594;file:///root/anaconda3/envs/yolodell/lib/python3.9/site-packages/lightning/pytorch/trainer/setup.py#169\u001b\\\u001b[2m169\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-10 00:07:36,578][lightning.pytorch.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs\n",
      "{'name': 'v9-dev', 'task': {'validation': {'task': 'validation', 'data': {'batch_size': 32, 'image_size': '${image_size}', 'cpu_num': '${cpu_num}', 'shuffle': False, 'pin_memory': True, 'data_augment': {}, 'dynamic_shape': False}, 'nms': {'min_confidence': 0.0001, 'min_iou': 0.7, 'max_bbox': 1000}}, 'task': 'train', 'epoch': 10, 'data': {'batch_size': 8, 'image_size': '${image_size}', 'cpu_num': '${cpu_num}', 'shuffle': True, 'pin_memory': True, 'data_augment': {'HorizontalFlip': 0.5}}, 'optimizer': {'type': 'SGD', 'args': {'lr': 1e-07, 'weight_decay': 0.0005, 'momentum': 0.937, 'nesterov': True}}, 'loss': {'objective': {'BCELoss': 0.5, 'BoxLoss': 7.5, 'DFLoss': 1.5}, 'aux': 0.25, 'matcher': {'iou': 'CIoU', 'topk': 10, 'factor': {'iou': 6.0, 'cls': 0.5}}}, 'scheduler': {'type': 'LinearLR', 'warmup': {'epochs': 3.0}, 'args': {'total_iters': '${task.epoch}', 'start_factor': 1, 'end_factor': 0.01}}, 'ema': {'enable': True, 'decay': 0.995}}, 'dataset': {'class_list': ['bench', 'generic object'], 'class_num': 2, 'path': 'data/processedDell', 'train': 'train2017', 'validation': 'val2017'}, 'model': {'name': 'v9-c', 'anchor': {'reg_max': 16, 'strides': [8, 16, 32]}, 'model': {'backbone': [{'Conv': {'args': {'out_channels': 64, 'kernel_size': 3, 'stride': 2}, 'source': 0}}, {'Conv': {'args': {'out_channels': 128, 'kernel_size': 3, 'stride': 2}}}, {'RepNCSPELAN': {'args': {'out_channels': 256, 'part_channels': 128}}}, {'ADown': {'args': {'out_channels': 256}}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 256}, 'tags': 'B3'}}, {'ADown': {'args': {'out_channels': 512}}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'B4'}}, {'ADown': {'args': {'out_channels': 512}}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'B5'}}], 'neck': [{'SPPELAN': {'args': {'out_channels': 512}, 'tags': 'N3'}}, {'UpSample': {'args': {'scale_factor': 2, 'mode': 'nearest'}}}, {'Concat': {'source': [-1, 'B4']}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'N4'}}, {'UpSample': {'args': {'scale_factor': 2, 'mode': 'nearest'}}}, {'Concat': {'source': [-1, 'B3']}}], 'head': [{'RepNCSPELAN': {'args': {'out_channels': 256, 'part_channels': 256}, 'tags': 'P3'}}, {'ADown': {'args': {'out_channels': 256}}}, {'Concat': {'source': [-1, 'N4']}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'P4'}}, {'ADown': {'args': {'out_channels': 512}}}, {'Concat': {'source': [-1, 'N3']}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'P5'}}], 'detection': [{'MultiheadDetection': {'source': ['P3', 'P4', 'P5'], 'tags': 'Main', 'output': True}}], 'auxiliary': [{'CBLinear': {'source': 'B3', 'args': {'out_channels': [256]}, 'tags': 'R3'}}, {'CBLinear': {'source': 'B4', 'args': {'out_channels': [256, 512]}, 'tags': 'R4'}}, {'CBLinear': {'source': 'B5', 'args': {'out_channels': [256, 512, 512]}, 'tags': 'R5'}}, {'Conv': {'args': {'out_channels': 64, 'kernel_size': 3, 'stride': 2}, 'source': 0}}, {'Conv': {'args': {'out_channels': 128, 'kernel_size': 3, 'stride': 2}}}, {'RepNCSPELAN': {'args': {'out_channels': 256, 'part_channels': 128}}}, {'ADown': {'args': {'out_channels': 256}}}, {'CBFuse': {'source': ['R3', 'R4', 'R5', -1], 'args': {'index': [0, 0, 0]}}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 256}, 'tags': 'A3'}}, {'ADown': {'args': {'out_channels': 512}}}, {'CBFuse': {'source': ['R4', 'R5', -1], 'args': {'index': [1, 1]}}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'A4'}}, {'ADown': {'args': {'out_channels': 512}}}, {'CBFuse': {'source': ['R5', -1], 'args': {'index': [2]}}}, {'RepNCSPELAN': {'args': {'out_channels': 512, 'part_channels': 512}, 'tags': 'A5'}}, {'MultiheadDetection': {'source': ['A3', 'A4', 'A5'], 'tags': 'AUX', 'output': True}}]}}, 'device': 0, 'cpu_num': 16, 'image_size': [640, 640], 'out_path': 'runs', 'exist_ok': True, 'lucky_number': 10, 'use_wandb': True, 'use_tensorboard': False, 'weight': True}\n"
     ]
    }
   ],
   "source": [
    "# Training based on the queried MixedDataset\n",
    "# For more params-setting, please check:\n",
    "# https://yolo-docs.readthedocs.io/en/latest/?badge=latest\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "%run yolo/lazy.py task=train task.data.batch_size=8 model=v9-c dataset=dellData task.epoch=10 weight=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "\n",
    "# command  = \"CUDA_VISIBLE_DEVICES=0 python yolo/lazy.py task=inference name=test device=cuda model=v9-c dataset=dellData task.nms.min_confidence=0.1 task.fast_inference=onnx task.data.source=data/processedDell/images/test2017/ weight='/jicheng_workspace/jicheng_notebook/YOLO/runs/train/v9-dev/YOLO/kf65nxvs/checkpoints/yolo.ckpt'\"\n",
    "\n",
    "# subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run yolo/lazy.py task=inference name=test device=cuda model=v9-c dataset=dellData \\\n",
    "# task.nms.min_confidence=0.1 task.fast_inference=onnx \\\n",
    "# task.data.source=data/processedDell/images/test2017/ \\\n",
    "# weight=\"'/jicheng_workspace/jicheng_notebook/YOLO/runs/train/v9-dev/YOLO/5t6dcono/checkpoints/epoch=9-step=120.ckpt'\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tutorials_detection_mmdetection(2)(10).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolodell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
